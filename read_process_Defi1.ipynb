{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition working directory (optionnel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/FR021091/Downloads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Défi 1 - Lecture des données (Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#afficher la liste des fichiers triés par date de modification\n",
    "#sorted(filter(os.path.isfile, os.listdir('.')), key=os.path.getmtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Liste des fichiers identifiés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    " 'validations-reseau-ferre-nombre-validations-par-jour-1er-semestre.csv',\n",
    " 'frequentation-gares.csv',\n",
    " 'validations-reseau-surface-nombre-validations-par-jour-1er-trimestre.csv',\n",
    " 'histo-validations-reseau-surface.csv',\n",
    " 'validations-reseau-ferre-profils-horaires-par-jour-type-1er-semestre.csv',\n",
    " 'comptage-voyageurs-trains-transilien.csv',\n",
    " 'validations-reseau-surface-nombre-validations-par-jour-2eme-trimestre.csv',\n",
    " 'comptage-multimodal-comptages.csv'\n",
    "]\n",
    "\n",
    "print(len(files),  len(list(set(files))) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lecture des fichiers identifiés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = {}\n",
    "\n",
    "for f__i in files:\n",
    "    print(f__i)\n",
    "    df__i = pd.read_csv(f__i,   sep = ';')\n",
    "    DATA[f__i] = df__i\n",
    "    print(df__i.shape)\n",
    "    print(df__i.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lecture des fichier zip (historique validations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archives =  ['data-rf-2019.zip',\n",
    " 'data-rf-2021.zip',\n",
    " 'data-rf-2017.zip',\n",
    " 'data-rf-2022.zip',\n",
    " 'data-rf-2018.zip',\n",
    " 'data-rf-2015.zip',\n",
    " 'data-rf-2016.zip',\n",
    " 'data-rf-2020.zip']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing des zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "\n",
    "\n",
    "def unzip(arch__i, output_dir=\"temp_unzip_folder\"):\n",
    "    print(\"=================================>\", arch__i)\n",
    "    with ZipFile(arch__i, 'r') as zf:\n",
    "        print(\"NAMELIST :       \", zf.namelist())\n",
    "        for file in zf.namelist():\n",
    "            print(file)\n",
    "            with zf.open(file) as f:\n",
    "                # Check if it's another ZIP and extract it to a temporary location\n",
    "                if file.endswith('.zip'):\n",
    "                    if not os.path.exists(output_dir):\n",
    "                        os.makedirs(output_dir, exist_ok = True)\n",
    "                    temp_path = os.path.join(output_dir, file)\n",
    "                    with open(temp_path, 'wb') as temp_file:\n",
    "                        temp_file.write(f.read())\n",
    "                    unzip(temp_path)\n",
    "                    os.remove(temp_path)\n",
    "                    continue\n",
    "                \n",
    "                if file.endswith('.txt'):\n",
    "                    sep = '\\t'\n",
    "                elif (file.endswith('.csv')) | (file in [\"data-rf-2022/2022_S2_PROFIL_FER.txt\", \"data-rf-2022/2022_S2_PROFIL_FER.txt\" ] ) :\n",
    "                    sep = ';'\n",
    "                else:\n",
    "                    continue  # Skip unknown file types\n",
    "                \n",
    "                df__i = pd.read_csv(f, sep=sep)\n",
    "                DATA[file] = df__i\n",
    "                \n",
    "                print(df__i.shape)\n",
    "                print(df__i.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "for arch__i in archives:\n",
    "    unzip(arch__i)    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données SNCF - Ligne H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DocumentationDonnées_Hackaton_IdFM_270923.xlsx',\n",
       " 'PDT&Comptage_2022_Hackaton_IdFM_280923.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"Donnees_sncf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "data_compt = pd.read_csv(os.path.join(\"Donnees_sncf\",   'PDT&Comptage_2022_Hackaton_IdFM_280923.csv'), sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Ligne', 'NumeroMarche_theorique', 'NumeroMarche_realise',\n",
       "       'pointJalonnement_rang_theorique', 'pointJalonnement_rang_realise',\n",
       "       'Libelle_PR', 'CodeTT0020Localite',\n",
       "       'pointJalonnement_pointHoraire_horairePrevu_depart_theorique',\n",
       "       'pointJalonnement_pointHoraire_horaireObserve_Depart_realise',\n",
       "       'pointJalonnement_pointHoraire_horairePrevu_Arrivee_theorique',\n",
       "       'pointJalonnement_pointHoraire_horaireObserve_Arrivee_realise',\n",
       "       'pointJalonnement_horairePrevuPassage_theorique',\n",
       "       'pointJalonnement_horairePrevuPassage_realise',\n",
       "       'pointJalonnement_horaireObservePassage_theorique',\n",
       "       'pointJalonnement_horaireObservePassage_realise', 'Date', 'Jour',\n",
       "       'Date_comptage', 'Ordre', 'Origine', 'Terminus', 'Mission',\n",
       "       'Heure_theorique', 'Occupation', 'Montees', 'Descentes',\n",
       "       'Nb_Places_assises_theorique', 'Nb_Places_totales_theorique',\n",
       "       'Tx_occup_places_tot', 'Tx_occup_places_assises',\n",
       "       'Composition_theorique', 'Nb_Voitures_theorique',\n",
       "       'Nb_Portes_theorique'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_compt.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_gares = pd.read_csv(\"referentiel-gares-voyageurs.csv\", sep =';')\n",
    "\n",
    "mapping1 = {}\n",
    "mapping1['VCX'] = 'VMS'\n",
    "mapping1['GNX'] = 'GRL'\n",
    "\n",
    "# Utilisation de la méthode map pour transformer la colonne\n",
    "ref_gares['TVS_transf'] = ref_gares['TVS'].map(mapping1)\n",
    "\n",
    "# Si vous souhaitez conserver les valeurs originales lorsqu'il n'y a pas de mapping:\n",
    "ref_gares['TVS_transf'].fillna(ref_gares['TVS'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {}\n",
    "mapping['PNB'] =  'PNO'\n",
    "mapping['VW'] =  'VWG'\n",
    "mapping['EN'] = 'ENK'\n",
    "mapping['NO'] = 'NOJ'\n",
    "mapping['CL'] = 'CLH'\n",
    "mapping['MLV'] = 'MVC'\n",
    "\n",
    "# Utilisation de la méthode map pour transformer la colonne\n",
    "data_compt['CodeTT0020Localite_transf'] = data_compt['CodeTT0020Localite'].map(mapping)\n",
    "\n",
    "# Si vous souhaitez conserver les valeurs originales lorsqu'il n'y a pas de mapping:\n",
    "data_compt['CodeTT0020Localite_transf'].fillna(data_compt['CodeTT0020Localite'], inplace=True)\n",
    "\n",
    "data_compt = pd.merge(data_compt, ref_gares, left_on = \"CodeTT0020Localite_transf\", right_on = \"TVS_transf\", how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Paris-Nord-Surface Bâtiment Voyageurs</td>\n",
       "      <td>PNB</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Villaines (Val-d'Oise) *00*</td>\n",
       "      <td>VW</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Viarmes *00*</td>\n",
       "      <td>VMS</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Enghien-les-Bains *00*</td>\n",
       "      <td>EN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Nointel-Mours *00*</td>\n",
       "      <td>NO</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Groslay *00*</td>\n",
       "      <td>GRL</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Creil Bâtiment Voyageurs</td>\n",
       "      <td>CL</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        0    1      2\n",
       "13  Paris-Nord-Surface Bâtiment Voyageurs  PNB  False\n",
       "14            Villaines (Val-d'Oise) *00*   VW  False\n",
       "18                           Viarmes *00*  VMS  False\n",
       "25                 Enghien-les-Bains *00*   EN  False\n",
       "36                     Nointel-Mours *00*   NO  False\n",
       "44                           Groslay *00*  GRL  False\n",
       "47               Creil Bâtiment Voyageurs   CL  False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bools = pd.DataFrame([( i__i ,c__i  , (c__i in ref_gares['TVS'].unique()) ) for i__i, c__i in zip( data_compt['Libelle_PR'].unique()  ,data_compt['CodeTT0020Localite'].unique() )])\n",
    "\n",
    "bools.loc[[not x for x in bools[2].tolist()] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_compt.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_dt_passage = \"pointJalonnement_pointHoraire_horaireObserve_Arrivee_realise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_compt = data_compt[~data_compt[\"pointJalonnement_pointHoraire_horaireObserve_Arrivee_realise\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FR021091\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def classify_hour(date_str):\n",
    "    # Vérifiez si la valeur est 'nan' ou autre valeur non valide\n",
    "    if pd.isna(date_str) or date_str == 'nan':\n",
    "        return \"Donnée manquante\"\n",
    "\n",
    "    # Convertissez la chaîne en objet datetime\n",
    "    try:\n",
    "        date_obj = datetime.strptime(date_str, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "    except ValueError:\n",
    "        return \"Format incorrect\"\n",
    "    \n",
    "    # Obtenez l'heure\n",
    "    hour = date_obj.hour\n",
    "    \n",
    "    # Vérifiez si l'heure est dans la plage d'heure de pointe\n",
    "    if (6 <= hour < 10) or (16 <= hour < 19):\n",
    "        return \"heure de pointe\"\n",
    "    else:\n",
    "        return \"pas heure de pointe\"\n",
    "\n",
    "\n",
    "\n",
    "data_compt['heure_pointe'] = [classify_hour(str(x)) for x in data_compt[ref_dt_passage] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['heure de pointe', 'pas heure de pointe'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_compt['heure_pointe'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = data_compt.copy(deep=True)\n",
    "agg['Date'] = pd.to_datetime(agg['Date'], format=\"%d/%m/%Y\")\n",
    "\n",
    "# Ajout du jour de la semaine\n",
    "agg['Weekday'] = agg['Date'].dt.strftime('%A')\n",
    "\n",
    "# Trier les données\n",
    "agg = agg.sort_values([\"Date\", \"NumeroMarche_realise\", \"pointJalonnement_rang_realise\"])\n",
    "\n",
    "# Créer la colonne \"Code UIC_shift\"\n",
    "agg['Code UIC_shift'] = agg.groupby([\"Date\", \"NumeroMarche_realise\"])['Code UIC'].shift(-1)\n",
    "\n",
    "# Filtrer les lignes avec des NaN dans \"Code UIC_shift\"\n",
    "agg_filtered = agg[agg['Code UIC_shift'].notna()][[\"Libelle_PR\" ,\"Code UIC\", \"Code UIC_shift\", 'Tx_occup_places_tot', \"Weekday\", 'heure_pointe', 'Latitude', 'Longitude']]\n",
    "\n",
    "# Grouper par \"Code UIC\", \"Code UIC_shift\" et \"Weekday\", et calculer la moyenne d'occupation\n",
    "Res = agg_filtered.groupby([\"Libelle_PR\" ,'Code UIC', 'Code UIC_shift', 'Weekday', 'heure_pointe', 'Latitude', 'Longitude'])['Tx_occup_places_tot'].mean().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Libelle_PR</th>\n",
       "      <th>Code UIC</th>\n",
       "      <th>Code UIC_shift</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>heure_pointe</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Tx_occup_places_tot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2882</th>\n",
       "      <td>Viarmes *00*</td>\n",
       "      <td>87276568.0</td>\n",
       "      <td>87276345.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>pas heure de pointe</td>\n",
       "      <td>49.116920</td>\n",
       "      <td>2.368380</td>\n",
       "      <td>0.007050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296</th>\n",
       "      <td>Seugy *00*</td>\n",
       "      <td>87272039.0</td>\n",
       "      <td>87276493.0</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>pas heure de pointe</td>\n",
       "      <td>49.118992</td>\n",
       "      <td>2.398912</td>\n",
       "      <td>0.005965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2292</th>\n",
       "      <td>Seugy *00*</td>\n",
       "      <td>87272039.0</td>\n",
       "      <td>87276436.0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>pas heure de pointe</td>\n",
       "      <td>49.118992</td>\n",
       "      <td>2.398912</td>\n",
       "      <td>0.005965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2285</th>\n",
       "      <td>Seugy *00*</td>\n",
       "      <td>87272039.0</td>\n",
       "      <td>87276360.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>pas heure de pointe</td>\n",
       "      <td>49.118992</td>\n",
       "      <td>2.398912</td>\n",
       "      <td>0.005965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>Seugy *00*</td>\n",
       "      <td>87272039.0</td>\n",
       "      <td>87272039.0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>pas heure de pointe</td>\n",
       "      <td>49.118992</td>\n",
       "      <td>2.398912</td>\n",
       "      <td>0.005965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2279</th>\n",
       "      <td>Seugy *00*</td>\n",
       "      <td>87272039.0</td>\n",
       "      <td>87271122.0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>pas heure de pointe</td>\n",
       "      <td>49.118992</td>\n",
       "      <td>2.398912</td>\n",
       "      <td>0.005965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>Montsoult-Maffliers Bâtiment Voyageurs</td>\n",
       "      <td>87276493.0</td>\n",
       "      <td>87272039.0</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>pas heure de pointe</td>\n",
       "      <td>49.066110</td>\n",
       "      <td>2.322290</td>\n",
       "      <td>0.004338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2923</th>\n",
       "      <td>Villaines (Val-d'Oise) *00*</td>\n",
       "      <td>87272021.0</td>\n",
       "      <td>87276394.0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>pas heure de pointe</td>\n",
       "      <td>49.079827</td>\n",
       "      <td>2.351374</td>\n",
       "      <td>0.004338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Belloy-St-Martin Bâtiment Voyageurs</td>\n",
       "      <td>87276550.0</td>\n",
       "      <td>87276394.0</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>pas heure de pointe</td>\n",
       "      <td>49.098070</td>\n",
       "      <td>2.361350</td>\n",
       "      <td>0.004338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>Paris-Nord-Surface Bâtiment Voyageurs</td>\n",
       "      <td>87271007.0</td>\n",
       "      <td>87271007.0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>pas heure de pointe</td>\n",
       "      <td>48.880185</td>\n",
       "      <td>2.355151</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Libelle_PR    Code UIC  Code UIC_shift  \\\n",
       "2882                            Viarmes *00*  87276568.0      87276345.0   \n",
       "2296                              Seugy *00*  87272039.0      87276493.0   \n",
       "2292                              Seugy *00*  87272039.0      87276436.0   \n",
       "2285                              Seugy *00*  87272039.0      87276360.0   \n",
       "2284                              Seugy *00*  87272039.0      87272039.0   \n",
       "2279                              Seugy *00*  87272039.0      87271122.0   \n",
       "1663  Montsoult-Maffliers Bâtiment Voyageurs  87276493.0      87272039.0   \n",
       "2923             Villaines (Val-d'Oise) *00*  87272021.0      87276394.0   \n",
       "70       Belloy-St-Martin Bâtiment Voyageurs  87276550.0      87276394.0   \n",
       "1918   Paris-Nord-Surface Bâtiment Voyageurs  87271007.0      87271007.0   \n",
       "\n",
       "        Weekday         heure_pointe   Latitude  Longitude  \\\n",
       "2882     Friday  pas heure de pointe  49.116920   2.368380   \n",
       "2296   Thursday  pas heure de pointe  49.118992   2.398912   \n",
       "2292  Wednesday  pas heure de pointe  49.118992   2.398912   \n",
       "2285     Friday  pas heure de pointe  49.118992   2.398912   \n",
       "2284    Tuesday  pas heure de pointe  49.118992   2.398912   \n",
       "2279     Monday  pas heure de pointe  49.118992   2.398912   \n",
       "1663   Thursday  pas heure de pointe  49.066110   2.322290   \n",
       "2923  Wednesday  pas heure de pointe  49.079827   2.351374   \n",
       "70     Thursday  pas heure de pointe  49.098070   2.361350   \n",
       "1918    Tuesday  pas heure de pointe  48.880185   2.355151   \n",
       "\n",
       "      Tx_occup_places_tot  \n",
       "2882             0.007050  \n",
       "2296             0.005965  \n",
       "2292             0.005965  \n",
       "2285             0.005965  \n",
       "2284             0.005965  \n",
       "2279             0.005965  \n",
       "1663             0.004338  \n",
       "2923             0.004338  \n",
       "70               0.004338  \n",
       "1918             0.000000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Res.sort_values('Tx_occup_places_tot', ascending= False).tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for h__i in Res['heure_pointe'].unique():\n",
    "    Res[Res['heure_pointe'] == h__i].to_csv(f'data_byWeekday_{h__i}.csv', sep = ',', encoding = 'utf-8-sig', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = data_compt.copy(deep = True)\n",
    "agg['Date'] = pd.to_datetime(agg['Date'], format = \"%d/%m/%Y\")\n",
    "\n",
    "for dt_fix in agg['Date'].unique():\n",
    "\n",
    "\n",
    "    agg = agg[(agg[\"Date\"] == dt_fix)]\n",
    "\n",
    "    Res = pd.DataFrame()\n",
    "    for m__i in agg[\"NumeroMarche_realise\"].unique():\n",
    "        agg__i = agg[(agg[\"NumeroMarche_realise\"] == m__i) ]\n",
    "\n",
    "\n",
    "        agg__i = agg__i.sort_values([\"NumeroMarche_realise\", \"pointJalonnement_rang_realise\"])\n",
    "\n",
    "        agg__i['Code UIC_shift'] = agg__i['Code UIC'].shift(-1)\n",
    "        agg__i = agg__i[[\"Code UIC\" ,  'Code UIC_shift',\"Occupation\"]].dropna()\n",
    "\n",
    "        Res = pd.concat([Res, agg__i], axis = 0)\n",
    "    Res = Res.groupby(['Code UIC', 'Code UIC_shift'])['Occupation'].mean().reset_index()\n",
    "\n",
    "print(Res.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Res = Res.groupby(['Code UIC', 'Code UIC_shift'])['Occupation'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_fix.strftime(\"%A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Res.to_csv(f'example_{dt_fix.strftime(\"%Y_%m_%d\")}.csv', sep = ',', encoding = 'utf-8-sig', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = data_compt.copy(deep = True).groupby([ \"pointJalonnement_rang_realise\" ,\"Intitulé gare\", \"Code UIC\", \"Latitude\", 'Longitude'])['Occupation'].mean().reset_index()\n",
    "\n",
    "\n",
    "print(agg.shape)\n",
    "print(agg.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_compt[data_compt['Intitulé gare'] == \"Marne-la-Vallée Chessy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Res.to_csv('res.csv', encoding = 'utf-8-sig', sep = ';', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_compt.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_compt.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_fix = pd.to_datetime(\"2022-01-05\")\n",
    "agg = data_compt.copy(deep = True)\n",
    "agg['Date'] = pd.to_datetime(agg['Date'], format = \"%d/%m/%Y\")\n",
    "agg = agg[(agg[\"Date\"] == dt_fix)]\n",
    "\n",
    "\n",
    "Res = pd.DataFrame()\n",
    "for m__i in agg[\"NumeroMarche_realise\"].unique():\n",
    "    agg__i = agg[(agg[\"NumeroMarche_realise\"] == m__i) ]\n",
    "    \n",
    "\n",
    "    agg__i = agg__i.sort_values([\"NumeroMarche_realise\", \"pointJalonnement_rang_realise\"])\n",
    "\n",
    "    agg__i['Code UIC_shift'] = agg__i['Code UIC'].shift(-1)\n",
    "    agg__i = agg__i[[\"NumeroMarche_realise\", \"pointJalonnement_rang_realise\" ,\"Code UIC\" ,  'Code UIC_shift',\"Occupation\"]]\n",
    "\n",
    "    Res = pd.concat([Res, agg__i], axis = 0)\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "agg[agg[\"NumeroMarche_realise\"] ==124006.0].sort_values([\"NumeroMarche_realise\", \"pointJalonnement_rang_realise\"]).to_csv('res.csv', encoding = 'utf-8-sig', sep = ';', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_compt[['CodeTT0020Localite_transf', \"Libelle_PR\", \"Intitulé gare\",  'TVS']].drop_duplicates().to_csv('res2.csv', encoding = 'utf-8-sig', sep = ';', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
